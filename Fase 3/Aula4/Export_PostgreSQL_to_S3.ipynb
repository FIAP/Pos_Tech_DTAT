{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "656a6bef",
   "metadata": {},
   "source": [
    "# 🐘 Exportação de Tabelas do PostgreSQL para o S3 (Camada Raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fd058e",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook conecta-se ao banco de dados PostgreSQL e exporta as tabelas:\n",
    "- `clientes`\n",
    "- `produtos`\n",
    "- `pedidos`\n",
    "- `itens_pedido`\n",
    "- `tipos_produto`\n",
    "\n",
    "Os dados são salvos na camada **raw** de um bucket S3 no formato `.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install psycopg2-binary pandas boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "635f9b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexão com o PostgreSQL estabelecida.\n",
      "Bucket 'aula-data-lake' já existe.\n",
      "Exportando tabela: clientes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/k_krjbt51f5106pgp409lg0m0000gn/T/ipykernel_86005/1455349903.py:56: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(f\"SELECT * FROM {tabela};\", conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ clientes salva no S3 em: s3://aula-data-lake/raw/clientes.csv\n",
      "Exportando tabela: produtos\n",
      "✅ produtos salva no S3 em: s3://aula-data-lake/raw/produtos.csv\n",
      "Exportando tabela: pedidos\n",
      "✅ pedidos salva no S3 em: s3://aula-data-lake/raw/pedidos.csv\n",
      "Exportando tabela: itens_pedido\n",
      "✅ itens_pedido salva no S3 em: s3://aula-data-lake/raw/itens_pedido.csv\n",
      "Exportando tabela: tipos_produto\n",
      "✅ tipos_produto salva no S3 em: s3://aula-data-lake/raw/tipos_produto.csv\n",
      "Exportação concluída com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import boto3\n",
    "from io import StringIO\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# === CONFIGURAÇÕES ===\n",
    "\n",
    "# PostgreSQL\n",
    "pg_config = {\n",
    "    \"host\": \"postgres-db.cu4mvwwdzs1u.us-east-1.rds.amazonaws.com\",\n",
    "    \"database\": \"db_relacional\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Fiap#2025\",\n",
    "    \"port\": 5432\n",
    "}\n",
    "\n",
    "# AWS S3\n",
    "bucket_name = \"aula-data-lake\"\n",
    "s3_prefix = \"raw/\"\n",
    "\n",
    "# Tabelas a exportar\n",
    "tabelas = ['clientes', 'produtos', 'pedidos', 'itens_pedido', 'tipos_produto']\n",
    "\n",
    "# === CONEXÃO COM POSTGRES ===\n",
    "\n",
    "conn = psycopg2.connect(**pg_config)\n",
    "print(\"Conexão com o PostgreSQL estabelecida.\")\n",
    "\n",
    "# === CONEXÃO COM S3 ===\n",
    "s3 = boto3.client('s3')\n",
    "region = s3.meta.region_name or \"us-east-1\"  # região do client S3\n",
    "\n",
    "# === VERIFICAR/CRIAR BUCKET ===\n",
    "try:\n",
    "    s3.head_bucket(Bucket=bucket_name)\n",
    "    print(f\"Bucket '{bucket_name}' já existe.\")\n",
    "except ClientError as e:\n",
    "    error_code = int(e.response['Error']['Code'])\n",
    "    if error_code == 404:\n",
    "        print(f\"Bucket '{bucket_name}' não existe. Criando...\")\n",
    "        if region == \"us-east-1\":\n",
    "            s3.create_bucket(Bucket=bucket_name)\n",
    "        else:\n",
    "            s3.create_bucket(\n",
    "                Bucket=bucket_name,\n",
    "                CreateBucketConfiguration={'LocationConstraint': region}\n",
    "            )\n",
    "        print(f\"Bucket '{bucket_name}' criado com sucesso.\")\n",
    "    else:\n",
    "        raise\n",
    "\n",
    "# === EXPORTAÇÃO ===\n",
    "for tabela in tabelas:\n",
    "    print(f\"Exportando tabela: {tabela}\")\n",
    "    df = pd.read_sql(f\"SELECT * FROM {tabela};\", conn)\n",
    "\n",
    "    # Salvar como CSV em memória\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    # Enviar para S3\n",
    "    s3_key = f\"{s3_prefix}{tabela}.csv\"\n",
    "    s3.put_object(Bucket=bucket_name, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "    print(f\"✅ {tabela} salva no S3 em: s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "# === FECHAR CONEXÃO ===\n",
    "conn.close()\n",
    "print(\"Exportação concluída com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🐘 Transferencia de arquivos CSV para as camadas do LakeHouse (Camada Silver e Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.2)\n",
      "Requirement already satisfied: pyarrow in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (15.0.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting s3fs\n",
      "  Downloading s3fs-2025.5.1-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/thiagogeneroso/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Collecting aiobotocore<3.0.0,>=2.5.4\n",
      "  Downloading aiobotocore-2.22.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from s3fs) (3.8.4)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "  Downloading aiohttp-3.12.12-cp311-cp311-macosx_11_0_arm64.whl (469 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.9/469.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting aioitertools<1.0.0,>=0.5.1\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.37.4,>=1.37.2\n",
      "  Downloading botocore-1.37.3-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (6.0.4)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs) (1.15.0)\n",
      "Collecting aiohappyeyeballs>=2.5.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (1.3.3)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.8/89.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/thiagogeneroso/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from botocore<1.37.4,>=1.37.2->aiobotocore<3.0.0,>=2.5.4->s3fs) (2.0.3)\n",
      "Requirement already satisfied: idna>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->s3fs) (3.4)\n",
      "Installing collected packages: propcache, fsspec, aioitertools, aiohappyeyeballs, yarl, botocore, aiohttp, aiobotocore, s3fs\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.2\n",
      "    Uninstalling yarl-1.9.2:\n",
      "      Successfully uninstalled yarl-1.9.2\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.106\n",
      "    Uninstalling botocore-1.34.106:\n",
      "      Successfully uninstalled botocore-1.34.106\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.4\n",
      "    Uninstalling aiohttp-3.8.4:\n",
      "      Successfully uninstalled aiohttp-3.8.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "boto3 1.34.71 requires botocore<1.35.0,>=1.34.71, but you have botocore 1.37.3 which is incompatible.\n",
      "chalice 1.27.1 requires attrs<21.5.0,>=19.3.0, but you have attrs 25.3.0 which is incompatible.\n",
      "awscli 1.32.106 requires botocore==1.34.106, but you have botocore 1.37.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiobotocore-2.22.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.12 aioitertools-0.12.0 botocore-1.37.3 fsspec-2025.5.1 propcache-0.3.2 s3fs-2025.5.1 yarl-1.20.1\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas pyarrow fsspec s3fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento das camadas Silver e Gold no S3 particionado por anomesdia finalizado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Para acessar S3, Pandas usa o s3fs automaticamente\n",
    "RAW_PREFIX = 's3://aula-data-lake/raw/'\n",
    "SILVER_PREFIX = 's3://aula-data-lake/silver/'\n",
    "GOLD_PREFIX = 's3://aula-data-lake/gold/'\n",
    "\n",
    "# 1. Silver Layer: Leitura e Limpeza dos Dados\n",
    "clientes = pd.read_csv(RAW_PREFIX + 'clientes.csv')\n",
    "produtos = pd.read_csv(RAW_PREFIX + 'produtos.csv')\n",
    "tipos_produto = pd.read_csv(RAW_PREFIX + 'tipos_produto.csv')\n",
    "pedidos = pd.read_csv(RAW_PREFIX + 'pedidos.csv')\n",
    "itens_pedido = pd.read_csv(RAW_PREFIX + 'itens_pedido.csv')\n",
    "\n",
    "# Padronizar colunas para lower case\n",
    "for df in [clientes, produtos, tipos_produto, pedidos, itens_pedido]:\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "# Limpeza básica\n",
    "clientes = clientes.drop_duplicates().dropna(subset=['id_cliente'])\n",
    "produtos = produtos.drop_duplicates().dropna(subset=['id_produto'])\n",
    "tipos_produto = tipos_produto.drop_duplicates().dropna(subset=['id_tipo'])\n",
    "pedidos = pedidos.drop_duplicates().dropna(subset=['id_pedido', 'id_cliente'])\n",
    "itens_pedido = itens_pedido.drop_duplicates().dropna(subset=['id_item', 'id_pedido', 'id_produto'])\n",
    "\n",
    "# Padronização de datas\n",
    "if 'data_pedido' in pedidos.columns:\n",
    "    pedidos['data_pedido'] = pd.to_datetime(pedidos['data_pedido'], errors='coerce')\n",
    "\n",
    "# Salvar camada Silver em Parquet no S3\n",
    "clientes.to_parquet(SILVER_PREFIX + 'clientes/', index=False)\n",
    "produtos.to_parquet(SILVER_PREFIX + 'produtos/', index=False)\n",
    "tipos_produto.to_parquet(SILVER_PREFIX + 'tipos_produto/', index=False)\n",
    "pedidos.to_parquet(SILVER_PREFIX + 'pedidos/', index=False)\n",
    "itens_pedido.to_parquet(SILVER_PREFIX + 'itens_pedido/', index=False)\n",
    "\n",
    "# 2. Gold Layer: Enriquecimento e Agregações\n",
    "\n",
    "# Fato de vendas com todas as dimensões\n",
    "gold_vendas = itens_pedido.merge(pedidos, on='id_pedido') \\\n",
    "    .merge(produtos, on='id_produto') \\\n",
    "    .merge(tipos_produto, on='id_tipo') \\\n",
    "    .merge(clientes, on='id_cliente')\n",
    "\n",
    "# Valor total do item\n",
    "if 'quantidade' in gold_vendas.columns and 'preco_unitario' in gold_vendas.columns:\n",
    "    gold_vendas['valor_total_item'] = gold_vendas['quantidade'] * gold_vendas['preco_unitario']\n",
    "\n",
    "# Criação do campo anomesdia\n",
    "if 'data_pedido' in gold_vendas.columns:\n",
    "    gold_vendas['anomesdia'] = gold_vendas['data_pedido'].dt.strftime('%Y%m%d')\n",
    "\n",
    "# Exemplo: Resumo por cliente\n",
    "gold_vendas_por_cliente = gold_vendas.groupby(['id_cliente', 'nome']) \\\n",
    "    .agg({'valor_total_item': 'sum', 'id_pedido': 'nunique'}) \\\n",
    "    .rename(columns={'valor_total_item': 'valor_total_comprado', 'id_pedido': 'num_pedidos'}) \\\n",
    "    .reset_index()\n",
    "\n",
    "# Exemplo: Resumo por tipo de produto\n",
    "gold_vendas_por_tipo = gold_vendas.groupby(['id_tipo', 'nome_tipo']) \\\n",
    "    .agg({'valor_total_item': 'sum', 'quantidade': 'sum'}) \\\n",
    "    .rename(columns={'valor_total_item': 'total_vendido', 'quantidade': 'quantidade_total'}) \\\n",
    "    .reset_index()\n",
    "\n",
    "# Salvar camada Gold no S3, particionando por anomesdia\n",
    "gold_vendas.to_parquet(GOLD_PREFIX + 'fato_vendas/', partition_cols=['anomesdia'], index=False)\n",
    "gold_vendas_por_cliente.to_parquet(GOLD_PREFIX + 'vendas_por_cliente/', index=False)\n",
    "gold_vendas_por_tipo.to_parquet(GOLD_PREFIX + 'vendas_por_tipo/', index=False)\n",
    "\n",
    "print(\"Processamento das camadas Silver e Gold no S3 particionado por anomesdia finalizado com sucesso!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
